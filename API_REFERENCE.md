# API Reference

> **Note:** This is public documentation for showcase purposes. Configure your own deployment for production use.

## Base URL

```
http://localhost:8000  # Local development
```

For production deployment, configure your own base URL and update CORS settings in `main.py`.

## Authentication

Currently uses API key authentication via environment variable:
```bash
export GEMINI_API_KEY='your-google-gemini-api-key'
```

## Endpoints

### Health Check

**GET** `/healthz`

Check if the API is running.

**Response:**
```json
{
  "status": "ok",
  "service": "phc-grant-assistant"
}
```

---

### Generate Answers

**POST** `/api/generate`

Generate answers for grant application questions using AI.

**Request Body:**
```json
{
  "grantQuestions": "Question 1\nQuestion 2\nQuestion 3",
  "grantContext": "Optional: Information about the grant sponsor, requirements, focus areas, etc."
}
```

**Parameters:**
- `grantQuestions` (string, required): Questions separated by newlines
- `grantContext` (string, optional): Additional context about the grant/sponsor

**Response:**
```json
{
  "results": [
    {
      "question": "Question 1",
      "answer": "Detailed answer generated by AI...",
      "sources": [
        "Quantitative → PHC Impact 2024",
        "Qualitative → PHC History"
      ]
    }
  ],
  "tailoring_explanation": "How responses were tailored to the sponsor...",
  "fit_score": 4.5,
  "fit_explanation": "Why this is a good fit for the sponsor..."
}
```

**Response Fields:**
- `results` (array): List of question-answer pairs with sources
  - `question` (string): The original question
  - `answer` (string): AI-generated answer
  - `sources` (array): Knowledge base sources used
- `tailoring_explanation` (string): How responses were customized (if context provided)
- `fit_score` (number): Fit rating 0-5 (if context provided)
- `fit_explanation` (string): Detailed fit analysis (if context provided)

**Example Request:**
```bash
curl -X POST "http://localhost:8000/api/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "grantQuestions": "What is your organization mission?",
    "grantContext": "This grant focuses on health equity and underserved populations."
  }'
```

---

## Interactive Documentation

When running locally, visit:
- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

## Error Responses

All endpoints return standard HTTP status codes:

**400 Bad Request:**
```json
{
  "detail": "No valid grant questions found in input."
}
```

**500 Internal Server Error:**
```json
{
  "detail": "GEMINI_API_KEY environment variable not set"
}
```

## Rate Limiting

⚠️ **Important:** This showcase version does not include rate limiting. For production:
- Implement rate limiting middleware
- Add authentication/authorization
- Configure appropriate quotas

## CORS Configuration

Update `main.py` to add your frontend domains:

```python
allow_origins=[
    "http://localhost:8080",
    "http://localhost:5173",
    "https://your-production-domain.com",  # Add your domain
]
```

## Frontend Integration

### React/TypeScript Example

```typescript
const response = await fetch('http://localhost:8000/api/generate', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    grantQuestions: "What is your mission?",
    grantContext: "Grant context here..."
  }),
});

const data = await response.json();
console.log(data.results);
```

### Python Example

```python
import requests

response = requests.post(
    'http://localhost:8000/api/generate',
    json={
        'grantQuestions': 'What is your mission?',
        'grantContext': 'Grant context here...'
    }
)

data = response.json()
print(data['results'])
```

## Knowledge Base

The API uses a knowledge base stored in the `knowledge_base/` directory:

```
knowledge_base/
├── quantitative/     # Statistical data, metrics
├── qualitative/      # Programs, history, approach
├── grant_example/    # Example grant applications
└── contact/          # Contact information
```

Add your own `.md` files to customize the knowledge base for your organization.

## Architecture

```
1. Frontend sends questions + context
2. Backend performs semantic search on knowledge base
3. Relevant chunks are retrieved via vector similarity
4. Chunks + questions sent to Google Gemini
5. AI generates comprehensive answers
6. Results returned with source attribution
```

## Dependencies

See `requirements.txt` for Python dependencies:
- FastAPI
- Google Generative AI (Gemini)
- NumPy
- Uvicorn

## Security Considerations

For production deployment:

1. ✅ Use environment variables for all secrets
2. ✅ Implement rate limiting
3. ✅ Add authentication/authorization
4. ✅ Configure CORS properly
5. ✅ Use HTTPS only
6. ✅ Validate all inputs
7. ✅ Monitor API usage
8. ✅ Set up logging and alerting

## Support

For questions about this showcase:
- See `README_RUN.md` for setup instructions
- See `SHOWCASE_NOTICE.md` for project information
- Open an issue for questions

---

**Last Updated:** 2025-11-18

